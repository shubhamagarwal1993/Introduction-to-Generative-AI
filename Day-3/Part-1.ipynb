{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Outline**\n",
    "\n",
    "\n",
    "- Overview of NLP: Understanding Language as Data\n",
    "- Language Generation Tasks\n",
    "  - Text Completion\n",
    "  - Text Generation\n",
    "  - Dialogue Systems\n",
    "  - Story Generation\n",
    "- Pre-trained Language Models \n",
    "  - Pre-trained Language Models (e.g., GPT, BERT)\n",
    "  - Fine-tuning for Language Generation Tasks\n",
    "- Using Hugging Face's Transformers Library for LLMs\n",
    "  - Adapting Pre-trained Models for Specific NLP Tasks\n",
    "- Capstone Project\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./images/border.jpg\" height=\"10\" width=\"1500\" align=\"center\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "- Our will focus on using Neural Networks to handle tasks related to **Natural Language Processing (NLP)**. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./images/border.jpg\" height=\"10\" width=\"1500\" align=\"center\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Natural Language Processing (NLP)**\n",
    "\n",
    "- Natural Language Processing (NLP) is a branch of artificial intelligence (AI).\n",
    "- It focuses on the interaction between computers and human language.\n",
    "- NLP enables computers to understand, process, and generate human language as data.\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./images/border.jpg\" height=\"10\" width=\"1500\" align=\"center\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Why NLP Matters**\n",
    "\n",
    "- NLP has practical applications in various domains:\n",
    "  - Customer service chatbots\n",
    "  - Sentiment analysis of social media data\n",
    "  - Language translation\n",
    "  - Content generation\n",
    "- It bridges the gap between human communication and AI systems.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./images/border.jpg\" height=\"10\" width=\"1500\" align=\"center\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **NLP Tasks**\n",
    "\n",
    "- NLP involves a range of tasks, including:\n",
    "  - Understanding language structure\n",
    "  - Text completion\n",
    "  - Text generation\n",
    "  - Dialogue systems (chatbots)\n",
    "  - Story generation\n",
    "- These tasks have real-world applications and are continuously evolving.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./images/border.jpg\" height=\"10\" width=\"1500\" align=\"center\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Understanding Language as Data**\n",
    "\n",
    "**Tokenization Example**\n",
    "\n",
    "- Tokenization is the process of splitting text into words or phrases.\n",
    "- It's a fundamental step in NLP.\n",
    "\n",
    "**Named Entity Recognition (NER) Demo**\n",
    "\n",
    "- Visit the [spaCy NER Demo](https://explosion.ai/demos/displacy-ent).\n",
    "- Input a sentence with named entities, e.g., \"Apple Inc. is headquartered in Cupertino, California.\"\n",
    "- Click \"Visualize\" to see entity recognition.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./images/border.jpg\" height=\"10\" width=\"1500\" align=\"center\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Language Generation Tasks**\n",
    "\n",
    "**Text Completion**\n",
    "\n",
    "- Demonstrated by Google Search's auto-suggestion feature.\n",
    "- It suggests the next word or phrase as you type your search query.\n",
    "\n",
    "**Text Generation**\n",
    "\n",
    "- Try the \"GPT-3 Playground\" by OpenAI.\n",
    "- Enter prompts like \"Once upon a time, in a land far, far away...\"\n",
    "- Click \"Create\" to generate creative text.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./images/border.jpg\" height=\"10\" width=\"1500\" align=\"center\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Dialogue Systems**\n",
    "\n",
    "**Chatbot Demo (Dialogflow)**\n",
    "\n",
    "- Go to [Dialogflow Console](https://console.cloud.google.com/dialogflow).\n",
    "- Create an agent with intents like \"Greeting.\"\n",
    "- Define responses like \"Hello! How can I assist you today?\"\n",
    "- Test your chatbot in real-time.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./images/border.jpg\" height=\"10\" width=\"1500\" align=\"center\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## **Story Generation**\n",
    "\n",
    "**Interactive Storytelling (AI Dungeon)**\n",
    "\n",
    "- Visit the [AI Dungeon](https://play.aidungeon.io/) website.\n",
    "- Choose a setting or genre (e.g., \"Fantasy\" or \"Mystery\").\n",
    "- Start a story with a sentence like \"You find yourself in a dark, enchanted forest...\"\n",
    "- AI generates the next part of the story for interactive storytelling.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./images/border.jpg\" height=\"10\" width=\"1500\" align=\"center\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Text Classification**\n",
    "\n",
    "* Text classification is a common task where text sequences are categorized.\n",
    "    * **Examples**:\n",
    "        * Classifying e-mails into **spam** or **no-spam**.\n",
    "        * Categorizing news articles into **sport**, **business**, **politics**, etc.\n",
    "\n",
    "* In chatbot development, it's crucial to comprehend user intent. This is termed as **intent classification**.\n",
    "    * **Example**:\n",
    "        * User says: \"How's the weather tomorrow?\"\n",
    "        * Bot understands the intent as: **Check Weather**\n",
    "\n",
    "Note: With intent classification, there can often be a multitude of categories.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./images/border.jpg\" height=\"10\" width=\"1500\" align=\"center\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Sentiment Analysis**\n",
    "\n",
    "* **Sentiment analysis** is typically a regression problem. The aim is to assign a numerical value representing the sentiment (how positive or negative) of a sentence.\n",
    "    * **Example**:\n",
    "        * Sentence: \"I love this product!\"\n",
    "        * Sentiment Score: +0.9 (where +1 is very positive and -1 is very negative)\n",
    "\n",
    "* An advanced form is **aspect-based sentiment analysis** (ABSA). Here, sentiment scores are given to different parts of the sentence.\n",
    "    * **Example**:\n",
    "        * Sentence: \"In this restaurant, I liked the cuisine, but the atmosphere was awful.\"\n",
    "        * Sentiments:\n",
    "            * Cuisine: +0.8\n",
    "            * Atmosphere: -0.9\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./images/border.jpg\" height=\"10\" width=\"1500\" align=\"center\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## **Keyword Extraction**\n",
    "\n",
    "* **Keyword extraction** is akin to NER. However, it focuses on automatically extracting words vital to a sentence's meaning, without any prior training on specific entity types.\n",
    "    * **Example**:\n",
    "        * Sentence: \"The Great Barrier Reef is a natural wonder located off the coast of Australia.\"\n",
    "        * Extracted Keywords: **Great Barrier Reef**, **natural wonder**, **coast**, **Australia**\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./images/border.jpg\" height=\"10\" width=\"1500\" align=\"center\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## **Text Clustering**\n",
    "\n",
    "* **Text clustering** involves grouping similar text sequences or sentences. It can be particularly helpful in contexts like grouping related inquiries in technical support interactions.\n",
    "    * **Example**:\n",
    "        * Tech Support Messages:\n",
    "            * \"My device won't turn on.\"\n",
    "            * \"I can't get my gadget to power up.\"\n",
    "            * \"How do I update my software?\"\n",
    "        * Clustered Results:\n",
    "            * Cluster 1: **Power issues** - \"My device won't turn on.\", \"I can't get my gadget to power up.\"\n",
    "            * Cluster 2: **Software updates** - \"How do I update my software?\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./images/border.jpg\" height=\"10\" width=\"1500\" align=\"center\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "## **Question Answering**\n",
    "\n",
    "* **Question answering** is about a model's capability to respond to a specific query. Given a text passage and a question, the model identifies the segment of the text containing the answer or, in some cases, generates the answer text.\n",
    "    * **Example**:\n",
    "        * Passage: \"The Eiffel Tower is located in Paris and was completed in 1889.\"\n",
    "        * Question: \"When was the Eiffel Tower completed?\"\n",
    "        * Answer: \"The Eiffel Tower was completed in **1889**.\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./images/border.jpg\" height=\"10\" width=\"1500\" align=\"center\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## **Text Generation**\n",
    "\n",
    "* **Text Generation** pertains to a model's ability to produce novel text. It's like a classification task predicting the next character or word based on a given *text prompt*.\n",
    "    * **Example**:\n",
    "        * Prompt: \"Once upon a time,\"\n",
    "        * Generated continuation: \"in a land far away, there lived a wise old dragon.\"\n",
    "\n",
    "* Advanced models, like GPT-3, can tackle other NLP tasks such as classification via techniques like [prompt programming](https://towardsdatascience.com/software-3-0-how-prompting-will-change-the-rules-of-the-game-a982fbfe1e0) or [prompt engineering](https://medium.com/swlh/openai-gpt-3-and-prompt-engineering-dcdc2c5fcd29).\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./images/border.jpg\" height=\"10\" width=\"1500\" align=\"center\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## **Text Summarization**\n",
    "\n",
    "* **Text summarization** is about enabling a computer to \"read\" lengthy text and condense it into a short, coherent summary.\n",
    "    * **Example**:\n",
    "        * Original Text: \"The solar system consists of the Sun and the objects that orbit it. These objects include planets, dwarf planets, moons, and asteroids. The largest planet in the solar system is Jupiter, while Mercury is the smallest.\"\n",
    "        * Summarized Text: \"The solar system includes the Sun, planets, and other celestial objects. Jupiter is the largest planet, and Mercury is the smallest.\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./images/border.jpg\" height=\"10\" width=\"1500\" align=\"center\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Machine Translation and NLP**\n",
    "\n",
    "* **Machine translation** is a blend of understanding text in one language and generating text in another.\n",
    "    * **Traditional Approach**:\n",
    "        1. Use parsers to convert a sentence into a syntax tree.\n",
    "        2. Extract higher-level semantic structures for the sentence's meaning.\n",
    "        3. Generate the translated output based on this meaning and the target language's grammar.\n",
    "    * **Modern Approach**: Use neural networks for more effective results in many NLP tasks.\n",
    "\n",
    "> Traditionally, many NLP tasks were tackled using methods like grammars. However, the paradigm has shifted towards neural network-based solutions in recent years.\n",
    "\n",
    "* **Resources**:\n",
    "    - Classical methods can be found in the [Natural Language Processing Toolkit (NLTK)](https://www.nltk.org).\n",
    "    - The [NLTK Book](https://www.nltk.org/book/) provides an online guide on solving NLP tasks using NLTK.\n",
    "\n",
    "* **Course Approach**:\n",
    "    * We will predominantly focus on Neural Networks for NLP and incorporate NLTK as required.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./images/border.jpg\" height=\"10\" width=\"1500\" align=\"center\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## **Neural Networks: From Images to Text**\n",
    "\n",
    "* **Tabular Data & Images**:\n",
    "    - We've explored using neural networks for fixed-size inputs like tabular data and images.\n",
    "    - Images have a predetermined input size.\n",
    "\n",
    "* **Text**:\n",
    "    - Text is a variable-length sequence, making it distinct.\n",
    "    - Textual patterns can be intricate. For instance, the distance between a subject and its negation can vary but should be recognized as a singular pattern.\n",
    "        * **Examples**:\n",
    "            - \"I do not like oranges.\"\n",
    "            - \"I do not like those big colorful tasty oranges.\"\n",
    "\n",
    "* **Solution for Text**:\n",
    "    - Traditional convolutional networks might not capture such complex patterns in text.\n",
    "    - To process language effectively, we introduce new neural architectures:\n",
    "        1. **Recurrent Networks**\n",
    "        2. **Transformers**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./images/border.jpg\" height=\"10\" width=\"1500\" align=\"center\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Representing Text**\n",
    "\n",
    "<img src=\"./images/ascii-character-map.png\" width=\"500\" align=\"center\"/>\n",
    "\n",
    "\n",
    "- To solve NLP tasks with neural networks, we need text representation as tensors.\n",
    "- Computers use encodings like ASCII or UTF-8 to map text characters to numbers.\n",
    "- Computers lack inherent understanding, and neural networks must learn meaning during training.\n",
    "- Two common approaches for text representation: \n",
    "  - character-level and word-level.\n",
    "- Regardless of approach, text is tokenized, converted to numbers, and fed into the network using one-hot encoding.\n",
    "\n",
    "\n",
    "## **N-Grams**\n",
    "\n",
    "- Precise word meanings depend on context (e.g., \"neural network\" vs. \"fishing network\").\n",
    "- Address context by considering pairs of words or even tri-grams.\n",
    "- This approach, called n-grams, increases dictionary size.\n",
    "- N-grams can also be used with character-level representation.\n",
    "\n",
    "<img src=\"./images/border.jpg\" height=\"10\" width=\"1500\" align=\"center\"/>\n",
    "\n",
    "## **Bag-of-Words and TF/IDF**\n",
    "\n",
    "\n",
    "<img src=\"images/bow.png\" width=\"90%\"/>\n",
    "\n",
    "\n",
    "- Text classification requires fixed-size vector representation.\n",
    "- Bag of Words (BoW) combines word representations, often using word frequencies.\n",
    "- BoW can indicate text content based on word frequencies.\n",
    "- TF/IDF (Term Frequency-Inverse Document Frequency) reduces the importance of common words.\n",
    "- TF/IDF considers word frequency across the document collection.\n",
    "\n",
    "<img src=\"./images/border.jpg\" height=\"10\" width=\"1500\" align=\"center\"/>\n",
    "\n",
    "## **Semantics of Text**\n",
    "\n",
    "- Existing approaches cannot fully capture text semantics.\n",
    "- More powerful neural network models are required.\n",
    "- Explore further in attached notebooks."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./images/border.jpg\" height=\"10\" width=\"1500\" align=\"center\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./images/NLP10.png\" align=\"center\"/>\n",
    "\n",
    "<img src=\"./images/NLP20.png\" align=\"center\"/>\n",
    "\n",
    "<img src=\"./images/NLP30.png\" align=\"center\"/>\n",
    "\n",
    "<img src=\"./images/NLP40.png\" align=\"center\"/>\n",
    "\n",
    "<img src=\"./images/NLP50.png\" align=\"center\"/>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./images/border.jpg\" height=\"10\" width=\"1500\" align=\"center\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchtext\n",
    "import os\n",
    "import collections\n",
    "os.makedirs('./data',exist_ok=True)\n",
    "train_dataset, test_dataset = torchtext.datasets.AG_NEWS(root='./data')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3,\n",
       " \"Wall St. Bears Claw Back Into the Black (Reuters) Reuters - Short-sellers, Wall Street's dwindling\\\\band of ultra-cynics, are seeing green again.\")"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classes = ['World', 'Sports', 'Business', 'Sci/Tech']\n",
    "list(train_dataset)[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because datasets are iterators, if we want to use the data multiple times we need to convert it to list:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset, test_dataset = torchtext.datasets.AG_NEWS(root='./data')\n",
    "train_dataset = list(train_dataset)\n",
    "test_dataset = list(test_dataset)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['he', 'said', 'hello']"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer = torchtext.data.utils.get_tokenizer('basic_english')\n",
    "tokenizer('He said: hello')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'>=' not supported between instances of 'list' and 'int'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/Users/mzihayat/VSC/Introduction-to-Generative-AI/Day-3/Part-1.ipynb Cell 46\u001b[0m line \u001b[0;36m4\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/mzihayat/VSC/Introduction-to-Generative-AI/Day-3/Part-1.ipynb#X61sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m \u001b[39mfor\u001b[39;00m (label, line) \u001b[39min\u001b[39;00m train_dataset:\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/mzihayat/VSC/Introduction-to-Generative-AI/Day-3/Part-1.ipynb#X61sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m     counter\u001b[39m.\u001b[39mupdate(tokenizer(line))\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/mzihayat/VSC/Introduction-to-Generative-AI/Day-3/Part-1.ipynb#X61sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m vocab \u001b[39m=\u001b[39m torchtext\u001b[39m.\u001b[39;49mvocab\u001b[39m.\u001b[39;49mvocab(counter, min_freq\u001b[39m=\u001b[39;49m\u001b[39m1\u001b[39;49m)\n",
      "File \u001b[0;32m~/VSC/Introduction-to-Generative-AI/.venv/lib/python3.9/site-packages/torchtext/vocab/vocab_factory.py:54\u001b[0m, in \u001b[0;36mvocab\u001b[0;34m(ordered_dict, min_freq, specials, special_first)\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[39m# Save room for special tokens\u001b[39;00m\n\u001b[1;32m     53\u001b[0m \u001b[39mfor\u001b[39;00m token, freq \u001b[39min\u001b[39;00m ordered_dict\u001b[39m.\u001b[39mitems():\n\u001b[0;32m---> 54\u001b[0m     \u001b[39mif\u001b[39;00m freq \u001b[39m>\u001b[39;49m\u001b[39m=\u001b[39;49m min_freq:\n\u001b[1;32m     55\u001b[0m         tokens\u001b[39m.\u001b[39mappend(token)\n\u001b[1;32m     57\u001b[0m \u001b[39mif\u001b[39;00m special_first:\n",
      "\u001b[0;31mTypeError\u001b[0m: '>=' not supported between instances of 'list' and 'int'"
     ]
    }
   ],
   "source": [
    "counter = collections.Counter()\n",
    "for (label, line) in train_dataset:\n",
    "    counter.update(tokenizer(line))\n",
    "vocab = torchtext.vocab.vocab(counter, min_freq=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using vocabulary, we can easily encode out tokenized string into a set of numbers:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocab size if 95810\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[599, 3279, 97, 1220, 329, 225, 7368]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab_size = len(vocab)\n",
    "print(f\"Vocab size if {vocab_size}\")\n",
    "\n",
    "stoi = vocab.get_stoi() # dict to convert tokens to indices\n",
    "\n",
    "def encode(x):\n",
    "    return [stoi[s] for s in tokenizer(x)]\n",
    "\n",
    "encode('I love to play with my words')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./images/border.jpg\" height=\"10\" width=\"1500\" align=\"center\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- BoW is a widely used traditional vector representation in text analysis.\n",
    "- Each word is associated with a vector index.\n",
    "- Vector elements store the count of word occurrences in a given document.\n",
    "![Image showing how a bag of words vector representation is represented in memory.](images/bag-of-words-example.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 1, 0, 2, 0, 0, 0, 0, 0]])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "vectorizer = CountVectorizer()\n",
    "corpus = [\n",
    "        'I like hot dogs.',\n",
    "        'The dog ran fast.',\n",
    "        'Its hot outside.',\n",
    "    ]\n",
    "vectorizer.fit_transform(corpus)\n",
    "vectorizer.transform(['My dog likes hot dogs on a hot day.']).toarray()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./images/border.jpg\" height=\"10\" width=\"1500\" align=\"center\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Word Embeddings**\n",
    "\n",
    "- When training classifiers based on BoW or TF/IDF, we work with high-dimensional one-hot encoded vectors of length `vocab_size`.\n",
    "- One-hot encoding is memory-inefficient and treats words independently, lacking semantic similarity.\n",
    "\n",
    "\n",
    "![Embedding and Semantic Similarity](images/NLP1.webp)\n",
    "\n",
    "- **Embedding** is the idea of representing words as lower-dimensional dense vectors that capture semantic meaning.\n",
    "- It reduces the dimensionality of word vectors.\n",
    "\n",
    "- The embedding layer takes a word as input and produces an output vector of specified `embedding_size`.\n",
    "- Unlike one-hot encoding, it takes a word number as input, avoiding large one-hot-encoded vectors.\n",
    "\n",
    "- Using an embedding layer as the first layer in a classifier network transforms it from a bag-of-words model to an **embedding bag** model.\n",
    "- In this model, words are converted into embeddings, and an aggregate function (e.g., `sum`, `average`, `max`) is applied to these embeddings.\n",
    "\n",
    "![Embedding Classifier Example](images/embedding-classifier-example.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./images/border.jpg\" height=\"10\" width=\"1500\" align=\"center\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Word Embeddings**\n",
    "\n",
    "- Early NLP models used word embeddings.\n",
    "- Each word mapped to a fixed-size vector.\n",
    "- Word2Vec, GloVe, and FastText were popular methods.\n",
    "\n",
    "\n",
    "- Word2Vec\n",
    "  - Word2Vec is a popular word embedding technique in natural language processing (NLP).\n",
    "  - It transforms words into dense vectors in a continuous vector space.\n",
    "  - Two main approaches: Skip-gram and Continuous Bag of Words (CBOW).\n",
    "  - Word2Vec captures semantic relationships and context between words.\n",
    "  - Used for various NLP tasks, including text classification, sentiment analysis, and recommendation systems."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting gensim\n",
      "  Obtaining dependency information for gensim from https://files.pythonhosted.org/packages/db/af/18b551ae8d26b8731dbe5923565fdf96502bb9aca88a37f241d510c62dc2/gensim-4.3.2-cp39-cp39-macosx_11_0_arm64.whl.metadata\n",
      "  Downloading gensim-4.3.2-cp39-cp39-macosx_11_0_arm64.whl.metadata (8.5 kB)\n",
      "Requirement already satisfied: numpy>=1.18.5 in /Users/mzihayat/VSC/Introduction-to-Generative-AI/.venv/lib/python3.9/site-packages (from gensim) (1.26.0)\n",
      "Requirement already satisfied: scipy>=1.7.0 in /Users/mzihayat/VSC/Introduction-to-Generative-AI/.venv/lib/python3.9/site-packages (from gensim) (1.11.3)\n",
      "Collecting smart-open>=1.8.1 (from gensim)\n",
      "  Obtaining dependency information for smart-open>=1.8.1 from https://files.pythonhosted.org/packages/fc/d9/d97f1db64b09278aba64e8c81b5d322d436132df5741c518f3823824fae0/smart_open-6.4.0-py3-none-any.whl.metadata\n",
      "  Downloading smart_open-6.4.0-py3-none-any.whl.metadata (21 kB)\n",
      "Downloading gensim-4.3.2-cp39-cp39-macosx_11_0_arm64.whl (24.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.0/24.0 MB\u001b[0m \u001b[31m7.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading smart_open-6.4.0-py3-none-any.whl (57 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.0/57.0 kB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: smart-open, gensim\n",
      "Successfully installed gensim-4.3.2 smart-open-6.4.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vector for 'learning':\n",
      " [ 7.0887972e-03 -1.5679300e-03  7.9474989e-03 -9.4886590e-03\n",
      " -8.0294991e-03 -6.6403709e-03 -4.0034545e-03  4.9892161e-03\n",
      " -3.8135587e-03 -8.3199050e-03  8.4117772e-03 -3.7470020e-03\n",
      "  8.6086961e-03 -4.8957514e-03  3.9185942e-03  4.9220170e-03\n",
      "  2.3926091e-03 -2.8188038e-03  2.8491246e-03 -8.2562361e-03\n",
      " -2.7655398e-03 -2.5911583e-03  7.2490061e-03 -3.4634031e-03\n",
      " -6.5997029e-03  4.3404270e-03 -4.7448516e-04 -3.5975564e-03\n",
      "  6.8824720e-03  3.8723124e-03 -3.9002013e-03  7.7188847e-04\n",
      "  9.1435025e-03  7.7546560e-03  6.3618720e-03  4.6673026e-03\n",
      "  2.3844899e-03 -1.8416261e-03 -6.3712932e-03 -3.0181051e-04\n",
      " -1.5653884e-03 -5.7228567e-04 -6.2628710e-03  7.4340473e-03\n",
      " -6.5914928e-03 -7.2392775e-03 -2.7571463e-03 -1.5154004e-03\n",
      " -7.6357173e-03  6.9824100e-04 -5.3261113e-03 -1.2755442e-03\n",
      " -7.3651113e-03  1.9605684e-03  3.2731986e-03 -2.3138524e-05\n",
      " -5.4483581e-03 -1.7260861e-03  7.0849168e-03  3.7362587e-03\n",
      " -8.8810492e-03 -3.4135508e-03  2.3541022e-03  2.1380198e-03\n",
      " -9.4640078e-03  4.5711659e-03 -8.6569972e-03 -7.3870681e-03\n",
      "  3.4831120e-03 -3.4709584e-03  3.5644709e-03  8.8940905e-03\n",
      " -3.5743224e-03  9.3204249e-03  1.7110384e-03  9.8477742e-03\n",
      "  5.7050432e-03 -9.1494834e-03 -3.3277308e-03  6.5301750e-03\n",
      "  5.6027793e-03  8.7055154e-03  6.9261026e-03  8.0388878e-03\n",
      " -9.8230084e-03  4.2988253e-03 -5.0300765e-03  3.5123860e-03\n",
      "  6.0566878e-03  4.3921317e-03  7.5123594e-03  1.4977157e-03\n",
      " -1.2649416e-03  5.7684006e-03 -5.6395675e-03  3.8591625e-05\n",
      "  9.4565870e-03 -5.4812501e-03  3.8142789e-03 -8.1130210e-03]\n",
      "Words similar to 'processing':\n",
      " [('natural', 0.06798139214515686), ('awesome', 0.033639226108789444)]\n"
     ]
    }
   ],
   "source": [
    "# Import necessary libraries\n",
    "from gensim.models import Word2Vec\n",
    "\n",
    "# Sample sentences for training the Word2Vec model\n",
    "sentences = [\n",
    "    [\"machine\", \"learning\", \"is\", \"awesome\"],\n",
    "    [\"word\", \"embeddings\", \"capture\", \"context\"],\n",
    "    [\"natural\", \"language\", \"processing\", \"rocks\"]\n",
    "]\n",
    "\n",
    "# Train a Word2Vec model\n",
    "model = Word2Vec(sentences, vector_size=100, window=5, min_count=1, sg=0)\n",
    "\n",
    "# Get the word vector for a specific word\n",
    "word_vector = model.wv['learning']\n",
    "print(\"Vector for 'learning':\\n\", word_vector)\n",
    "\n",
    "# Find similar words to a given word\n",
    "similar_words = model.wv.most_similar('processing', topn=2)\n",
    "print(\"Words similar to 'processing':\\n\", similar_words)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./images/border.jpg\" height=\"10\" width=\"1500\" align=\"center\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## **Limitations of Word Embeddings**\n",
    "  - Fixed-length vectors don't capture context well.\n",
    "  - Struggle with polysemy (multiple meanings).\n",
    "  - Limited understanding of word relationships.\n",
    "\n",
    "## **Transformers**\n",
    "\n",
    "  - The Transformer architecture revolutionized NLP.\n",
    "  - Introduced self-attention mechanisms.\n",
    "  - Captures context and dependencies effectively.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./images/border.jpg\" height=\"10\" width=\"1500\" align=\"center\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transformer Timeline\n",
    "\n",
    "\n",
    "![Embedding Classifier Example](images/NLP2.svg)\n",
    "\n",
    "- June 2017\n",
    "  - Introduction of the Transformer architecture\n",
    "\n",
    "- June 2018\n",
    "  - **GPT** (Generative Pretrained Transformer)\n",
    "  - First pretrained Transformer model\n",
    "  - Used for fine-tuning on NLP tasks\n",
    "  - Achieved state-of-the-art results\n",
    "\n",
    "- October 2018\n",
    "  - **BERT** (Bidirectional Encoder Representations from Transformers)\n",
    "  - Large pretrained model\n",
    "  - Designed for better sentence summarization\n",
    "  - More on this in the next chapter!\n",
    "\n",
    "- February 2019\n",
    "  - **GPT-2**\n",
    "  - Improved and larger version of GPT\n",
    "  - Delayed public release due to ethical concerns\n",
    "\n",
    "- October 2019\n",
    "  - **DistilBERT**\n",
    "  - Distilled version of BERT\n",
    "  - 60% faster, 40% lighter in memory\n",
    "  - Still retains 97% of BERT's performance\n",
    "\n",
    "  - **BART and T5**\n",
    "    - Large pretrained models\n",
    "    - Same architecture as the original Transformer\n",
    "\n",
    "- May 2020\n",
    "  - **GPT-3**\n",
    "  - Even bigger than GPT-2\n",
    "  - Performs well on various tasks without fine-tuning\n",
    "  - Known for zero-shot learning\n",
    "\n",
    "<img src=\"./images/border.jpg\" height=\"10\" width=\"1500\" align=\"center\"/>\n",
    "\n",
    "## **Transformer Model Types**\n",
    "\n",
    "- **GPT-like**\n",
    "  - Also known as auto-regressive Transformer models\n",
    "\n",
    "- **BERT-like**\n",
    "  - Also known as auto-encoding Transformer models\n",
    "\n",
    "- **BART/T5-like**\n",
    "  - Also known as sequence-to-sequence Transformer models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./images/border.jpg\" height=\"10\" width=\"1500\" align=\"center\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Pretrained Transformer Models**\n",
    "\n",
    "- All mentioned models (GPT, BERT, BART, T5, etc.) are pretrained language models.\n",
    "- Trained on large amounts of raw text data.\n",
    "- Self-supervised learning: Objective computed automatically from inputs, no human labeling required.\n",
    "\n",
    "- Limitations of Pretrained Models\n",
    "\n",
    "    - Pretrained models have statistical language understanding.\n",
    "    - Not directly useful for specific tasks.\n",
    "    - Require transfer learning for practical applications.\n",
    "\n",
    "- Transfer Learning\n",
    "\n",
    "  - Transfer learning fine-tunes pretrained models for specific tasks.\n",
    "  - Supervised learning with human-annotated labels.\n",
    "  - Improves model performance and adaptability.\n",
    "\n",
    "- Example Task:\n",
    "  -  Causal Language Modeling\n",
    "\n",
    "     - Task: Predict the next word in a sentence given n previous words.\n",
    "     - Output depends on past and present inputs, not future ones.\n",
    "\n",
    "![Embedding Classifier Example](images/NLP3.svg)\n",
    "\n",
    "\n",
    "  - Another example is masked language modeling, in which the model predicts a masked word in the sentence.\n",
    "\n",
    "\n",
    "\n",
    "![Embedding Classifier Example](images/NLP4.svg)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./images/border.jpg\" height=\"10\" width=\"1500\" align=\"center\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Transformers are big models**\n",
    "\n",
    "- Improving performance often involves:\n",
    "  - Increasing model sizes\n",
    "  - Expanding pretrained data\n",
    "\n",
    "![Embedding Classifier Example](images/NLP5.png)\n",
    "\n",
    "- Size vs. Performance\n",
    "  - Larger models tend to perform better.\n",
    "  - But training large models is resource-intensive.\n",
    "\n",
    "\n",
    "- Environmental Impact\n",
    "\n",
    "  - Large models have a significant carbon footprint.\n",
    "  - Time, compute resources, and environmental costs.\n",
    "  - Even efforts to reduce impact still result in substantial costs.\n",
    "\n",
    "\n",
    "\n",
    "- The Need for Sharing\n",
    "  - Sharing pretrained models is crucial.\n",
    "  - Reduces overall compute cost and carbon footprint.\n",
    "  - Benefits research teams, student organizations, and companies.\n",
    "\n",
    "<img src=\"./images/border.jpg\" height=\"10\" width=\"1500\" align=\"center\"/>\n",
    "\n",
    "## **Evaluate Carbon Footprint**\n",
    "\n",
    "- Tools available to evaluate carbon footprint:\n",
    "  - ML CO2 Impact\n",
    "  - Code Carbon (integrated in 🤗 Transformers)\n",
    "  \n",
    "![Embedding Classifier Example](images/NLP6.svg)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./images/border.jpg\" height=\"10\" width=\"1500\" align=\"center\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Pretraining vs. Fine-Tuning**\n",
    "\n",
    "- Pretraining\n",
    "    - Pretraining uses a large corpus of data.\n",
    "    - Training can take several weeks.\n",
    "\n",
    "\n",
    "![Embedding Classifier Example](images/NLP7.svg)\n",
    "\n",
    "- Fine-Tuning\n",
    "  - Fine-tuning occurs after pretraining.\n",
    "  - Utilizes a pretrained language model.\n",
    "  - Additional training with a task-specific dataset.\n",
    "\n",
    "\n",
    "![Embedding Classifier Example](images/NLP8.svg)\n",
    "\n",
    "- Why Not Direct Training?\n",
    "  - Pretrained models have some similarities with fine-tuning data.\n",
    "  - Fine-tuning leverages knowledge from pretraining.\n",
    "  - Requires less data, time, and resources.\n",
    "\n",
    "- Example Scenario\n",
    "  - Pretrained model in English.\n",
    "  - Fine-tuning on arXiv corpus.\n",
    "  - Creates a science/research-based model.\n",
    "  - Limited data needed for fine-tuning.\n",
    "\n",
    "- Transfer Learning\n",
    "\n",
    "  - Knowledge from pretraining \"transferred\" to fine-tuning.\n",
    "  - Effective way to adapt pretrained models to specific tasks."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./images/border.jpg\" height=\"10\" width=\"1500\" align=\"center\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **General architecture**\n",
    "\n",
    "- Two main components:\n",
    "  - Autoencoders\n",
    "  - Attention layers\n",
    "\n",
    "### **Autoencoders**\n",
    "\n",
    "![Transformer Architecture](images/NLP10.svg)\n",
    "\n",
    "\n",
    "<img src=\"./images/border.jpg\" height=\"10\" width=\"1500\" align=\"center\"/>\n",
    "\n",
    "### **Attention Layers**\n",
    "\n",
    "- Attention layers instruct the model to focus on specific words in a sentence while processing the representation of each word.\n",
    "- They help the model pay attention to certain words while ignoring others.\n",
    "- In the context of translation\n",
    "  - Attention layers are crucial because they allow the model to consider adjacent words for proper translation.\n",
    "  - For example\n",
    "    - When translating from English to French, attention is needed for subjects and gender agreement.\n",
    "- Attention layers ensure that words' meanings are deeply influenced by their surrounding context.\n",
    "\n",
    "- They are essential for handling complex sentences and grammar rules in natural language processing tasks.\n",
    "\n",
    "- Understanding attention layers is a foundation for comprehending the Transformer architecture.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./images/border.jpg\" height=\"10\" width=\"1500\" align=\"center\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **The Transformer**\n",
    "\n",
    "![Transformer Architecture](images/NLP9.svg)\n",
    "\n",
    "- Transformer architecture designed for translation.\n",
    "- **Encoder** processes inputs (sentences) in one language.\n",
    "- **Decoder** generates translations in the target language.\n",
    "\n",
    "-  **Attention Mechanism in Encoder**\n",
    "   - Encoder uses attention layers.\n",
    "   - Can attend to all words in a sentence.\n",
    "   - Considers both preceding and following words.\n",
    "  \n",
    "- **Attention Mechanism in Decoder**\n",
    "\n",
    "  - Decoder works sequentially.\n",
    "  - Processes words one by one.\n",
    "  - Limited to using words before the current word.\n",
    "\n",
    "- Training Speed-up\n",
    "\n",
    "  - During training, the decoder sees the entire target sentence.\n",
    "  - It can't use future words for prediction.\n",
    "  - For example, when predicting the fourth word, it only has access to words 1 to 3.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./images/border.jpg\" height=\"10\" width=\"1500\" align=\"center\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word Embeddings Shape: torch.Size([1, 8, 768])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import BertTokenizer, BertModel\n",
    "\n",
    "# Load pre-trained BERT tokenizer and model\n",
    "model_name = \"bert-base-uncased\"\n",
    "tokenizer = BertTokenizer.from_pretrained(model_name)\n",
    "model = BertModel.from_pretrained(model_name)\n",
    "\n",
    "# Input text\n",
    "text = \"Hello, how are you doing today?\"\n",
    "\n",
    "# Tokenize input text\n",
    "tokens = tokenizer.tokenize(text)\n",
    "input_ids = tokenizer.convert_tokens_to_ids(tokens)\n",
    "input_ids = torch.tensor(input_ids).unsqueeze(0)  # Add batch dimension\n",
    "\n",
    "# Forward pass through BERT model\n",
    "outputs = model(input_ids)\n",
    "\n",
    "# Get the output embeddings (contextualized word representations)\n",
    "word_embeddings = outputs.last_hidden_state\n",
    "\n",
    "# Print the shape of the word embeddings\n",
    "print(\"Word Embeddings Shape:\", word_embeddings.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./images/border.jpg\" height=\"10\" width=\"1500\" align=\"center\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Semantic Similarity Analysis using BERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch in /Users/mzihayat/VSC/Introduction-to-Generative-AI/.venv/lib/python3.9/site-packages (2.0.1)\n",
      "Collecting transformers\n",
      "  Obtaining dependency information for transformers from https://files.pythonhosted.org/packages/1a/d1/3bba59606141ae808017f6fde91453882f931957f125009417b87a281067/transformers-4.34.0-py3-none-any.whl.metadata\n",
      "  Downloading transformers-4.34.0-py3-none-any.whl.metadata (121 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m121.5/121.5 kB\u001b[0m \u001b[31m7.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: filelock in /Users/mzihayat/VSC/Introduction-to-Generative-AI/.venv/lib/python3.9/site-packages (from torch) (3.12.4)\n",
      "Requirement already satisfied: typing-extensions in /Users/mzihayat/VSC/Introduction-to-Generative-AI/.venv/lib/python3.9/site-packages (from torch) (4.8.0)\n",
      "Requirement already satisfied: sympy in /Users/mzihayat/VSC/Introduction-to-Generative-AI/.venv/lib/python3.9/site-packages (from torch) (1.12)\n",
      "Requirement already satisfied: networkx in /Users/mzihayat/VSC/Introduction-to-Generative-AI/.venv/lib/python3.9/site-packages (from torch) (3.1)\n",
      "Requirement already satisfied: jinja2 in /Users/mzihayat/VSC/Introduction-to-Generative-AI/.venv/lib/python3.9/site-packages (from torch) (3.1.2)\n",
      "Collecting huggingface-hub<1.0,>=0.16.4 (from transformers)\n",
      "  Obtaining dependency information for huggingface-hub<1.0,>=0.16.4 from https://files.pythonhosted.org/packages/aa/f3/3fc97336a0e90516901befd4f500f08d691034d387406fdbde85bea827cc/huggingface_hub-0.17.3-py3-none-any.whl.metadata\n",
      "  Downloading huggingface_hub-0.17.3-py3-none-any.whl.metadata (13 kB)\n",
      "Requirement already satisfied: numpy>=1.17 in /Users/mzihayat/VSC/Introduction-to-Generative-AI/.venv/lib/python3.9/site-packages (from transformers) (1.26.0)\n",
      "Requirement already satisfied: packaging>=20.0 in /Users/mzihayat/VSC/Introduction-to-Generative-AI/.venv/lib/python3.9/site-packages (from transformers) (23.2)\n",
      "Collecting pyyaml>=5.1 (from transformers)\n",
      "  Obtaining dependency information for pyyaml>=5.1 from https://files.pythonhosted.org/packages/0e/88/21b2f16cb2123c1e9375f2c93486e35fdc86e63f02e274f0e99c589ef153/PyYAML-6.0.1-cp39-cp39-macosx_11_0_arm64.whl.metadata\n",
      "  Using cached PyYAML-6.0.1-cp39-cp39-macosx_11_0_arm64.whl.metadata (2.1 kB)\n",
      "Collecting regex!=2019.12.17 (from transformers)\n",
      "  Obtaining dependency information for regex!=2019.12.17 from https://files.pythonhosted.org/packages/cd/98/999f0456bdb4124b3d0a7f1d8b6d50979536f5df9856e597580dd9a6d3ff/regex-2023.10.3-cp39-cp39-macosx_11_0_arm64.whl.metadata\n",
      "  Downloading regex-2023.10.3-cp39-cp39-macosx_11_0_arm64.whl.metadata (40 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m40.9/40.9 kB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: requests in /Users/mzihayat/VSC/Introduction-to-Generative-AI/.venv/lib/python3.9/site-packages (from transformers) (2.31.0)\n",
      "Collecting tokenizers<0.15,>=0.14 (from transformers)\n",
      "  Obtaining dependency information for tokenizers<0.15,>=0.14 from https://files.pythonhosted.org/packages/b9/18/c43b543f35403473ff7f4b703cc2a6f234dfe6ca1d9cd46d5e853666a095/tokenizers-0.14.0-cp39-cp39-macosx_11_0_arm64.whl.metadata\n",
      "  Downloading tokenizers-0.14.0-cp39-cp39-macosx_11_0_arm64.whl.metadata (6.7 kB)\n",
      "Collecting safetensors>=0.3.1 (from transformers)\n",
      "  Obtaining dependency information for safetensors>=0.3.1 from https://files.pythonhosted.org/packages/e4/b5/792a8ba02aac23bf4c500467016472775085c616d0fc5f30aa70037380c3/safetensors-0.3.3-cp39-cp39-macosx_13_0_arm64.whl.metadata\n",
      "  Using cached safetensors-0.3.3-cp39-cp39-macosx_13_0_arm64.whl.metadata (4.7 kB)\n",
      "Requirement already satisfied: tqdm>=4.27 in /Users/mzihayat/VSC/Introduction-to-Generative-AI/.venv/lib/python3.9/site-packages (from transformers) (4.66.1)\n",
      "Collecting fsspec (from huggingface-hub<1.0,>=0.16.4->transformers)\n",
      "  Obtaining dependency information for fsspec from https://files.pythonhosted.org/packages/fe/d3/e1aa96437d944fbb9cc95d0316e25583886e9cd9e6adc07baad943524eda/fsspec-2023.9.2-py3-none-any.whl.metadata\n",
      "  Downloading fsspec-2023.9.2-py3-none-any.whl.metadata (6.7 kB)\n",
      "Collecting huggingface-hub<1.0,>=0.16.4 (from transformers)\n",
      "  Obtaining dependency information for huggingface-hub<1.0,>=0.16.4 from https://files.pythonhosted.org/packages/7f/c4/adcbe9a696c135578cabcbdd7331332daad4d49b7c43688bc2d36b3a47d2/huggingface_hub-0.16.4-py3-none-any.whl.metadata\n",
      "  Downloading huggingface_hub-0.16.4-py3-none-any.whl.metadata (12 kB)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Users/mzihayat/VSC/Introduction-to-Generative-AI/.venv/lib/python3.9/site-packages (from jinja2->torch) (2.1.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/mzihayat/VSC/Introduction-to-Generative-AI/.venv/lib/python3.9/site-packages (from requests->transformers) (3.3.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/mzihayat/VSC/Introduction-to-Generative-AI/.venv/lib/python3.9/site-packages (from requests->transformers) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/mzihayat/VSC/Introduction-to-Generative-AI/.venv/lib/python3.9/site-packages (from requests->transformers) (2.0.6)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/mzihayat/VSC/Introduction-to-Generative-AI/.venv/lib/python3.9/site-packages (from requests->transformers) (2023.7.22)\n",
      "Requirement already satisfied: mpmath>=0.19 in /Users/mzihayat/VSC/Introduction-to-Generative-AI/.venv/lib/python3.9/site-packages (from sympy->torch) (1.3.0)\n",
      "Downloading transformers-4.34.0-py3-none-any.whl (7.7 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.7/7.7 MB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0mm\n",
      "\u001b[?25hUsing cached PyYAML-6.0.1-cp39-cp39-macosx_11_0_arm64.whl (174 kB)\n",
      "Downloading regex-2023.10.3-cp39-cp39-macosx_11_0_arm64.whl (291 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m291.0/291.0 kB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hUsing cached safetensors-0.3.3-cp39-cp39-macosx_13_0_arm64.whl (407 kB)\n",
      "Downloading tokenizers-0.14.0-cp39-cp39-macosx_11_0_arm64.whl (2.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m1.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m0m\n",
      "\u001b[?25hDownloading huggingface_hub-0.16.4-py3-none-any.whl (268 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m268.8/268.8 kB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading fsspec-2023.9.2-py3-none-any.whl (173 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m173.4/173.4 kB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: safetensors, regex, pyyaml, fsspec, huggingface-hub, tokenizers, transformers\n",
      "Successfully installed fsspec-2023.9.2 huggingface-hub-0.16.4 pyyaml-6.0.1 regex-2023.10.3 safetensors-0.3.3 tokenizers-0.14.0 transformers-4.34.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install torch transformers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import BertTokenizer, BertModel\n",
    "from scipy.spatial.distance import cosine\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading (…)/main/tokenizer.json: 100%|██████████| 466k/466k [00:00<00:00, 667kB/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "BertModel(\n",
       "  (embeddings): BertEmbeddings(\n",
       "    (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "    (position_embeddings): Embedding(512, 768)\n",
       "    (token_type_embeddings): Embedding(2, 768)\n",
       "    (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       "  (encoder): BertEncoder(\n",
       "    (layer): ModuleList(\n",
       "      (0-11): 12 x BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (intermediate_act_fn): GELUActivation()\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (pooler): BertPooler(\n",
       "    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "    (activation): Tanh()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load pre-trained model and tokenizer\n",
    "model_name = 'bert-base-uncased'\n",
    "model = BertModel.from_pretrained(model_name)\n",
    "tokenizer = BertTokenizer.from_pretrained(model_name)\n",
    "\n",
    "# Ensure the model is in eval mode\n",
    "model.eval()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_sentence(sentence):\n",
    "    # Tokenize the sentence and obtain output from BERT\n",
    "    inputs = tokenizer(sentence, return_tensors=\"pt\", truncation=True, padding=True, max_length=512)\n",
    "    with torch.no_grad():\n",
    "        out = model(**inputs)\n",
    "    \n",
    "    # Use the [CLS] embedding as sentence representation and convert it to 1D numpy array\n",
    "    return out['last_hidden_state'][:, 0, :].squeeze().numpy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_similarity(sentence1, sentence2):\n",
    "    # Encode sentences\n",
    "    embed1 = encode_sentence(sentence1)\n",
    "    embed2 = encode_sentence(sentence2)\n",
    "    \n",
    "    # Compute cosine similarity\n",
    "    similarity = 1 - cosine(embed1, embed2)\n",
    "    \n",
    "    return similarity\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Similarity between sentence1 and sentence2: 0.9554281830787659\n",
      "Similarity between sentence1 and sentence3: 0.9376117587089539\n"
     ]
    }
   ],
   "source": [
    "sentence1 = \"I love to play football.\"\n",
    "sentence2 = \"Soccer is my favorite sport.\"\n",
    "sentence3 = \"I love eating pasta.\"\n",
    "\n",
    "print(\"Similarity between sentence1 and sentence2:\", compute_similarity(sentence1, sentence2))\n",
    "print(\"Similarity between sentence1 and sentence3:\", compute_similarity(sentence2, sentence3))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./images/border.jpg\" height=\"10\" width=\"1500\" align=\"center\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **BERT Text Classification**\n",
    "\n",
    "\n",
    "\n",
    "### **Step 1: Load Pre-trained BERT**\n",
    "\n",
    "- Import necessary libraries.\n",
    "- Load pre-trained BERT tokenizer and model (e.g., `bert-base-uncased`).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import BertTokenizer, BertForSequenceClassification\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Load pre-trained BERT tokenizer and model\n",
    "model_name = \"bert-base-uncased\"\n",
    "tokenizer = BertTokenizer.from_pretrained(model_name)\n",
    "model = BertForSequenceClassification.from_pretrained(model_name, num_labels=2)  # 2 for binary classification\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./images/border.jpg\" height=\"10\" width=\"1500\" align=\"center\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## **Step 2: Prepare Training Data**\n",
    "\n",
    "- Define sample training data and labels.\n",
    "- Tokenize and encode the training data using the BERT tokenizer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample training data\n",
    "texts = [\"This is a positive review.\", \"This is a negative review.\"]\n",
    "labels = [1, 0]  # 1 for positive, 0 for negative\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./images/border.jpg\" height=\"10\" width=\"1500\" align=\"center\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Step 3: Create DataLoader**\n",
    "\n",
    "- Create a DataLoader for efficient training.\n",
    "- Set batch size and shuffle the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "/Users/mzihayat/VSC/Seshat/.conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Tokenize and encode the training data\n",
    "input_ids = []\n",
    "attention_masks = []\n",
    "\n",
    "for text in texts:\n",
    "    encoded_text = tokenizer.encode_plus(\n",
    "        text,\n",
    "        add_special_tokens=True,\n",
    "        max_length=128,\n",
    "        pad_to_max_length=True,\n",
    "        return_attention_mask=True,\n",
    "        return_tensors=\"pt\"\n",
    "    )\n",
    "    input_ids.append(encoded_text['input_ids'])\n",
    "    attention_masks.append(encoded_text['attention_mask'])\n",
    "\n",
    "input_ids = torch.cat(input_ids, dim=0)\n",
    "attention_masks = torch.cat(attention_masks, dim=0)\n",
    "labels = torch.tensor(labels)\n",
    "\n",
    "# Create a DataLoader for training data\n",
    "batch_size = 2\n",
    "train_dataset = TensorDataset(input_ids, attention_masks, labels)\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./images/border.jpg\" height=\"10\" width=\"1500\" align=\"center\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## **Step 4: Fine-Tune BERT**\n",
    "\n",
    "- Set up optimization (e.g., AdamW) and training parameters.\n",
    "- Iterate through epochs, compute loss, and update model weights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3, Average Loss: 0.9963\n",
      "Epoch 2/3, Average Loss: 0.7213\n",
      "Epoch 3/3, Average Loss: 0.6345\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Fine-tuning BERT on the classification task (you can adjust the number of training epochs)\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=2e-5)\n",
    "num_epochs = 3\n",
    "\n",
    "model.train()\n",
    "for epoch in range(num_epochs):\n",
    "    total_loss = 0\n",
    "    for batch in train_loader:\n",
    "        input_ids, attention_mask, label = batch\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(input_ids, attention_mask=attention_mask, labels=label)\n",
    "        loss = outputs.loss\n",
    "        total_loss += loss.item()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    average_loss = total_loss / len(train_loader)\n",
    "    print(f\"Epoch {epoch + 1}/{num_epochs}, Average Loss: {average_loss:.4f}\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./images/border.jpg\" height=\"10\" width=\"1500\" align=\"center\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## **Step 5: Evaluation**\n",
    "\n",
    "- Switch to evaluation mode.\n",
    "- Tokenize and encode sample test data.\n",
    "- Make predictions and calculate classification metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted Labels: tensor([0, 0])\n",
      "True Labels: [1 0]\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.50      1.00      0.67         1\n",
      "           1       0.00      0.00      0.00         1\n",
      "\n",
      "    accuracy                           0.50         2\n",
      "   macro avg       0.25      0.50      0.33         2\n",
      "weighted avg       0.25      0.50      0.33         2\n",
      "\n",
      "Accuracy: 0.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mzihayat/VSC/Seshat/.conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/mzihayat/VSC/Seshat/.conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/mzihayat/VSC/Seshat/.conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 600x400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Evaluation\n",
    "model.eval()\n",
    "test_texts = [\"This movie is great.\", \"I didn't like the film.\"]\n",
    "true_labels = [1, 0]\n",
    "\n",
    "test_input_ids = []\n",
    "test_attention_masks = []\n",
    "\n",
    "for text in test_texts:\n",
    "    encoded_text = tokenizer.encode_plus(\n",
    "        text,\n",
    "        add_special_tokens=True,\n",
    "        max_length=128,\n",
    "        pad_to_max_length=True,\n",
    "        return_attention_mask=True,\n",
    "        return_tensors=\"pt\"\n",
    "    )\n",
    "    test_input_ids.append(encoded_text['input_ids'])\n",
    "    test_attention_masks.append(encoded_text['attention_mask'])\n",
    "\n",
    "test_input_ids = torch.cat(test_input_ids, dim=0)\n",
    "test_attention_masks = torch.cat(test_attention_masks, dim=0)\n",
    "true_labels = torch.tensor(true_labels)\n",
    "\n",
    "with torch.no_grad():\n",
    "    logits = model(test_input_ids, attention_mask=test_attention_masks).logits\n",
    "\n",
    "predicted_labels = np.argmax(logits, axis=1)\n",
    "print(\"Predicted Labels:\", predicted_labels)\n",
    "print(\"True Labels:\", true_labels.numpy())\n",
    "\n",
    "# Classification report and accuracy\n",
    "classification_rep = classification_report(true_labels.numpy(), predicted_labels)\n",
    "accuracy = accuracy_score(true_labels.numpy(), predicted_labels)\n",
    "print(\"Classification Report:\\n\", classification_rep)\n",
    "print(\"Accuracy:\", accuracy)\n",
    "\n",
    "# Visualization\n",
    "fig, ax = plt.subplots(figsize=(6, 4))\n",
    "labels = ['Negative', 'Positive']\n",
    "y_pos = np.arange(len(labels))\n",
    "scores = [logits[0][0].item(), logits[1][1].item()]\n",
    "ax.bar(y_pos, scores, align='center', alpha=0.5)\n",
    "ax.set_ylabel('Scores')\n",
    "ax.set_xticks(y_pos)\n",
    "ax.set_xticklabels(labels)\n",
    "ax.set_title('BERT Sentiment Classification')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./images/border.jpg\" height=\"10\" width=\"1500\" align=\"center\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Text Generation: OpenAI GPT Model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'generated_text': 'Hello! I am a neural network, and I want to say that i am very grateful to you for coming up with this amazing idea. i am sure the company will enjoy my findings. and i am sure your brilliant, creative suggestions will be noted. \" \\n \" great! i love your idea, and you know the rest. i have already called the company to say that i am in agreement to this idea. i\\'m so pleased with your new vision, and i hope to hear from you'},\n",
       " {'generated_text': 'Hello! I am a neural network, and I want to say that you could say that. \" \\n \" all right! \" shouted rip. \" it\\'s us! we\\'re the greegs! we\\'re you! \" the greegs cheered wildly when the audience erupted into applause. \\n \" we are, \" said wilx. \" we are! \" \\n \" can you give us a song? \" asked wilx. \\n \" sure, \" said rip. \" you got us in here'},\n",
       " {'generated_text': 'Hello! I am a neural network, and I want to say that i don\\'t care about your life, even though it\\'s nice to be surrounded by these people. as i said, i don\\'t care about your life. \" \\n she smiled in a friendly sort of way as her fingers moved up to the collar pocket of his short dress shirt, her lips brushing over his neck, making the hairs rise along his jaw. he felt like someone had punched his stomach. \\n \" this can\\'t'},\n",
       " {'generated_text': 'Hello! I am a neural network, and I want to say that i am quite capable of coordinating all the communications and information via my neural network via any system present. the problem is, you see, the ai does not allow me to communicate from planet to planet. there is such a thing as an inability to communicate. this is a common problem for us in the outer worlds, even though it is entirely our fault that you are under a direct threat. the ai is very aware of it and'},\n",
       " {'generated_text': 'Hello! I am a neural network, and I want to say that everything is alright. we have plenty of information you can use and we will only be doing something we know you are a part of. if you wish, we would be happy to help. \" \\n \" it is a great honor, mr. belkin. yes, i would like to meet him. \" she put her hand on the arm of the couch and he pulled a chair next to her. \" please sit? please,'}]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "model_name = 'openai-gpt' \n",
    "\n",
    "generator = pipeline('text-generation', model=model_name)\n",
    "\n",
    "generator(\"Hello! I am a neural network, and I want to say that\", max_length=100, num_return_sequences=5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'generated_text': 'Synonyms of a word cat: \" - dog. cats are as cute as kittens. \"'},\n",
       " {'generated_text': \"Synonyms of a word cat:'little,'as if the cat were a cat.\"},\n",
       " {'generated_text': 'Synonyms of a word cat: \" cat \" and \" cat, \" as if they were'},\n",
       " {'generated_text': 'Synonyms of a word cat: what a thing to wake up to. \" yes, \"'},\n",
       " {'generated_text': 'Synonyms of a word cat: a phrase of love. or at least, i guess it'}]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generator(\"Synonyms of a word cat:\", max_length=20, num_return_sequences=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'generated_text': 'I love when you say this -> Positive\\nI have myself -> Negative\\nThis is awful for you to say this -> positive was the word i wanted to hear from him, when i was sure'},\n",
       " {'generated_text': \"I love when you say this -> Positive\\nI have myself -> Negative\\nThis is awful for you to say this -> positive i have i have you. you say'yes ', you have\"},\n",
       " {'generated_text': 'I love when you say this -> Positive\\nI have myself -> Negative\\nThis is awful for you to say this -> negative this is horrible - you need to go away, now, now -'},\n",
       " {'generated_text': \"I love when you say this -> Positive\\nI have myself -> Negative\\nThis is awful for you to say this -> positive - > negative - > negative - > i always have been i 'll\"},\n",
       " {'generated_text': \"I love when you say this -> Positive\\nI have myself -> Negative\\nThis is awful for you to say this -> positive i'm in a different room, > positive is good, positive is\"}]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generator(\"I love when you say this -> Positive\\nI have myself -> Negative\\nThis is awful for you to say this ->\", max_length=40, num_return_sequences=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'generated_text': 'Translate English to French: cat => chat, dog => chien, student =>  game between the french and americans : chess, games,'},\n",
       " {'generated_text': 'Translate English to French: cat => chat, dog => chien, student =>  cat = > cat = > feline, teacher = >'},\n",
       " {'generated_text': \"Translate English to French: cat => chat, dog => chien, student =>  friend, \\n '... and in writing this, as\"}]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generator(\"Translate English to French: cat => chat, dog => chien, student => \", top_k=50, max_length=30, num_return_sequences=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'generated_text': 'People who liked the movie The Matrix also liked  the movie, so if you ables that was an understatement. \\n ( the first movie by james taylor, which has not been shown yet, is called zombie'},\n",
       " {'generated_text': 'People who liked the movie The Matrix also liked  some classic movies about the time that their husband went, a lot of money was spent and the whole family could have a nice little vacation. it was only'},\n",
       " {'generated_text': 'People who liked the movie The Matrix also liked  the matrix. that made them two different kinds of people. the first version was really weird, and the other version was totally true. \\n \" i do'},\n",
       " {'generated_text': \"People who liked the movie The Matrix also liked  it the godfather. i figured that's why they did the movie instead of the godfather. i guess the movie just came from the cinema. the movie itself\"},\n",
       " {'generated_text': \"People who liked the movie The Matrix also liked  the movie the cia. i'm not sure what was in the film, but i didn't like what it was doing. even the actors in it were\"}]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generator(\"People who liked the movie The Matrix also liked \", max_length=40, num_return_sequences=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./images/border.jpg\" height=\"10\" width=\"1500\" align=\"center\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Text Sampling Strategies**\n",
    "\n",
    "So far we have been using simple **greedy** sampling strategy, when we selected next word based on the highest probability. Here is how it works:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'generated_text': \"It was early evening when I can back from work. I usually work late, but this time it was an exception. When I entered a room, I saw two people sitting in front of each other on a bed. they were facing each other on the bed and all of them were covered with a large quilt that was draped over the bed. they heard me enter, but didn't look up, so i went back to the kitchen. i could see them right away, and they both turned to\"},\n",
       " {'generated_text': 'It was early evening when I can back from work. I usually work late, but this time it was an exception. When I entered a room, I saw an array of paintings on display. as i entered them, i found the same one that i felt i had, only it was a different painting. it was of a beautiful castle surrounded by trees. i felt the feeling that the garden had been changed by the scene. the garden looked more like a painting in a museum since its design was'},\n",
       " {'generated_text': 'It was early evening when I can back from work. I usually work late, but this time it was an exception. When I entered a room, I saw my father, sitting at the head of the tables, eating food and drinking alcohol. his suit was black and made him look like a bad businessman that had come on too strong. his hair was white as the sky and his clothes were white as the snow around his feet. \\n he glanced up suddenly and saw me in the doorway and raised'},\n",
       " {'generated_text': 'It was early evening when I can back from work. I usually work late, but this time it was an exception. When I entered a room, I saw that only half of them were awake and i was surprised when they all noticed me. the one sitting on the left half of the bed, the one on the left half of the bed, stared at me wide - eyed, seemingly at a loss for words. \\n i walked down the hall and sat on the edge of the bed, trying'},\n",
       " {'generated_text': \"It was early evening when I can back from work. I usually work late, but this time it was an exception. When I entered a room, I saw i was the only one in there. my heart sped up at the sight of her gorgeous body and i didn't want to let her go. it felt so good to be near her, so right to touch her. she turned her head, and i could see the desire in her eyes. when she looked into my eyes, i knew\"}]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt = \"It was early evening when I can back from work. I usually work late, but this time it was an exception. When I entered a room, I saw\"\n",
    "generator(prompt,max_length=100,num_return_sequences=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Beam Search** allows the generator to explore several directions (*beams*) of text generation, and select the ones with highers overall score. You can do beam search by providing `num_beams` parameter. You can also specify `no_repeat_ngram_size` to penalize the model for repeating n-grams of a given size: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'generated_text': 'It was early evening when I can back from work. I usually work late, but this time it was an exception. When I entered a room, I saw a man sitting on the edge of the bed. he had his back to me, so i couldn\\'t tell if he was sleeping or not. \\n \" hi, \" i said. \" can i help you? \" \\n he turned around and looked at me. his eyes were a deep, dark brown, almost black, and they were'},\n",
       " {'generated_text': 'It was early evening when I can back from work. I usually work late, but this time it was an exception. When I entered a room, I saw a man sitting on the edge of the bed. he had his back to me, so i couldn\\'t tell if he was sleeping or not. \\n \" hi, \" i said. \" can i help you? \" \\n he turned around and looked at me. his eyes were a deep, dark brown, almost black, and his hair'},\n",
       " {'generated_text': 'It was early evening when I can back from work. I usually work late, but this time it was an exception. When I entered a room, I saw a man sitting on the edge of the bed. he had his back to me, so i couldn\\'t tell if he was sleeping or not. \\n \" hi, \" i said. \" can i help you? \" \\n he turned around and looked at me. his eyes were a deep blue, and his hair was a light brown.'},\n",
       " {'generated_text': 'It was early evening when I can back from work. I usually work late, but this time it was an exception. When I entered a room, I saw a man sitting on the edge of the bed. he had his back to me, so i couldn\\'t tell if he was sleeping or not. \\n \" hi, \" i said. \" can i help you? \" \\n he turned around and looked at me. his eyes were a deep, dark brown, almost black, and his skin'},\n",
       " {'generated_text': 'It was early evening when I can back from work. I usually work late, but this time it was an exception. When I entered a room, I saw a man sitting on the edge of the bed. he had his back to me, so i couldn\\'t tell if he was sleeping or not. \\n \" hi, \" i said. \" can i help you? \" \\n he turned around and looked at me. his eyes were a deep, dark brown, almost black. they were filled'}]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt = \"It was early evening when I can back from work. I usually work late, but this time it was an exception. When I entered a room, I saw\"\n",
    "generator(prompt,max_length=100,num_return_sequences=5,num_beams=10,no_repeat_ngram_size=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Sampling** selects the next word non-deterministically, using the probability distribution returned by the model. You turn on sampling using `do_sample=True` parameter. You can also specify `temperature`, to make the model more or less deterministic."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'generated_text': \"It was early evening when I can back from work. I usually work late, but this time it was an exception. When I entered a room, I saw a girl in a purple dress, holding a baby. the baby was asleep. the next thing i knew, i was running into the room and the baby was in her arms. the nurse came in, took the baby, and i'm in the hospital with my fiancee. why would this be happening to me, i don't know,\"}]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt = \"It was early evening when I can back from work. I usually work late, but this time it was an exception. When I entered a room, I saw\"\n",
    "generator(prompt,max_length=100,do_sample=True,temperature=0.8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also provide to additional parameters to sampling:\n",
    "* `top_k` specifies the number of word options to consider when using sampling. This minimizes the chance of getting weird (low-probability) words in our text.\n",
    "* `top_p` is similar, but we chose the smallest subset of most probable words, whose total probability is larger than p.\n",
    "\n",
    "Feel free to experiment with adding those parameters in."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./images/border.jpg\" height=\"10\" width=\"1500\" align=\"center\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Using OpenAI's GPT with Hugging Face's Transformers**\n",
    "\n",
    "\n",
    "**OpenAI's Generative Pretrained Transformer (GPT):**\n",
    "- A state-of-the-art language model using Transformer architecture.\n",
    "- Trained on vast amounts of text and can generate human-like text.\n",
    "- Has multiple versions (e.g., GPT-2, GPT-3) with increasing model sizes and capabilities.\n",
    "\n",
    "**Hugging Face's Transformers:**\n",
    "- A popular library for Natural Language Processing.\n",
    "- Provides pre-trained models, including GPT variants.\n",
    "- Facilitates easy fine-tuning, usage, and deployment of models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./images/border.jpg\" height=\"10\" width=\"1500\" align=\"center\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **1. Setup**\n",
    "\n",
    "First, make sure you have the necessary packages installed:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "Requirement already satisfied: transformers in /Users/mzihayat/VSC/Seshat/.conda/lib/python3.10/site-packages (4.33.2)\n",
      "Requirement already satisfied: torch in /Users/mzihayat/VSC/Seshat/.conda/lib/python3.10/site-packages (2.0.1)\n",
      "Requirement already satisfied: filelock in /Users/mzihayat/VSC/Seshat/.conda/lib/python3.10/site-packages (from transformers) (3.12.4)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.15.1 in /Users/mzihayat/VSC/Seshat/.conda/lib/python3.10/site-packages (from transformers) (0.17.2)\n",
      "Requirement already satisfied: numpy>=1.17 in /Users/mzihayat/VSC/Seshat/.conda/lib/python3.10/site-packages (from transformers) (1.25.2)\n",
      "Requirement already satisfied: packaging>=20.0 in /Users/mzihayat/VSC/Seshat/.conda/lib/python3.10/site-packages (from transformers) (23.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /Users/mzihayat/VSC/Seshat/.conda/lib/python3.10/site-packages (from transformers) (6.0.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /Users/mzihayat/VSC/Seshat/.conda/lib/python3.10/site-packages (from transformers) (2023.8.8)\n",
      "Requirement already satisfied: requests in /Users/mzihayat/VSC/Seshat/.conda/lib/python3.10/site-packages (from transformers) (2.31.0)\n",
      "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /Users/mzihayat/VSC/Seshat/.conda/lib/python3.10/site-packages (from transformers) (0.13.3)\n",
      "Requirement already satisfied: safetensors>=0.3.1 in /Users/mzihayat/VSC/Seshat/.conda/lib/python3.10/site-packages (from transformers) (0.3.3)\n",
      "Requirement already satisfied: tqdm>=4.27 in /Users/mzihayat/VSC/Seshat/.conda/lib/python3.10/site-packages (from transformers) (4.66.1)\n",
      "Requirement already satisfied: typing-extensions in /Users/mzihayat/VSC/Seshat/.conda/lib/python3.10/site-packages (from torch) (4.7.1)\n",
      "Requirement already satisfied: sympy in /Users/mzihayat/VSC/Seshat/.conda/lib/python3.10/site-packages (from torch) (1.12)\n",
      "Requirement already satisfied: networkx in /Users/mzihayat/VSC/Seshat/.conda/lib/python3.10/site-packages (from torch) (3.1)\n",
      "Requirement already satisfied: jinja2 in /Users/mzihayat/VSC/Seshat/.conda/lib/python3.10/site-packages (from torch) (3.1.2)\n",
      "Requirement already satisfied: fsspec in /Users/mzihayat/VSC/Seshat/.conda/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.15.1->transformers) (2023.9.1)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Users/mzihayat/VSC/Seshat/.conda/lib/python3.10/site-packages (from jinja2->torch) (2.1.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/mzihayat/VSC/Seshat/.conda/lib/python3.10/site-packages (from requests->transformers) (3.2.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/mzihayat/VSC/Seshat/.conda/lib/python3.10/site-packages (from requests->transformers) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/mzihayat/VSC/Seshat/.conda/lib/python3.10/site-packages (from requests->transformers) (2.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/mzihayat/VSC/Seshat/.conda/lib/python3.10/site-packages (from requests->transformers) (2023.7.22)\n",
      "Requirement already satisfied: mpmath>=0.19 in /Users/mzihayat/VSC/Seshat/.conda/lib/python3.10/site-packages (from sympy->torch) (1.3.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install transformers torch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **2. Importing required modules**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import GPT2Tokenizer, GPT2LMHeadModel\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./images/border.jpg\" height=\"10\" width=\"1500\" align=\"center\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **3. Initializing the tokenizer and model**\n",
    "\n",
    "Hugging Face has tokenizers and models pre-trained on various tasks. For this tutorial, we'll focus on GPT-2:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading (…)olve/main/vocab.json: 100%|██████████| 1.04M/1.04M [00:00<00:00, 12.4MB/s]\n",
      "Downloading (…)olve/main/merges.txt: 100%|██████████| 456k/456k [00:00<00:00, 6.51MB/s]\n",
      "Downloading (…)lve/main/config.json: 100%|██████████| 718/718 [00:00<00:00, 2.47MB/s]\n",
      "Downloading model.safetensors: 100%|██████████| 1.52G/1.52G [03:10<00:00, 7.98MB/s]\n",
      "Downloading (…)neration_config.json: 100%|██████████| 124/124 [00:00<00:00, 594kB/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GPT2LMHeadModel(\n",
       "  (transformer): GPT2Model(\n",
       "    (wte): Embedding(50257, 1024)\n",
       "    (wpe): Embedding(1024, 1024)\n",
       "    (drop): Dropout(p=0.1, inplace=False)\n",
       "    (h): ModuleList(\n",
       "      (0-23): 24 x GPT2Block(\n",
       "        (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPT2Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPT2MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (act): NewGELUActivation()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (ln_f): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "  )\n",
       "  (lm_head): Linear(in_features=1024, out_features=50257, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load pre-trained GPT-2 tokenizer\n",
    "tokenizer = GPT2Tokenizer.from_pretrained(\"gpt2-medium\")\n",
    "\n",
    "# Load the pre-trained GPT-2 model\n",
    "model = GPT2LMHeadModel.from_pretrained(\"gpt2-medium\")\n",
    "\n",
    "# Ensure the model is in eval mode (important for models with dropout or batchnorm)\n",
    "model.eval()\n",
    "\n",
    "# If you have a GPU available, move the model there\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./images/border.jpg\" height=\"10\" width=\"1500\" align=\"center\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **4. Generate text given a prompt**\n",
    "\n",
    "To generate text with GPT-2:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Once upon a time, there was a man who lived in a village called Krakow. He was a very good man, and he was very kind to his children. One day, he was walking along the road, and he saw a woman walking by. He asked her if she was his daughter. She said yes, and she said that she was his daughter. He asked her if she was his wife. She said yes, and she said that she was his wife. He asked her\n"
     ]
    }
   ],
   "source": [
    "def generate_text(prompt, max_length=100, temperature=1.0):\n",
    "    # Encode the prompt text to tensor\n",
    "    input_ids = tokenizer.encode(prompt, return_tensors=\"pt\").to(device)\n",
    "\n",
    "    # Generate text using the model\n",
    "    with torch.no_grad():\n",
    "        generated_ids = model.generate(input_ids=input_ids, max_length=max_length, num_return_sequences=1, temperature=temperature)[0]\n",
    "\n",
    "    # Decode the tensor to a text string\n",
    "    generated_text = tokenizer.decode(generated_ids, skip_special_tokens=True)\n",
    "    return generated_text\n",
    "\n",
    "# Try it out!\n",
    "prompt = \"Once upon a time\"\n",
    "print(generate_text(prompt))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./images/border.jpg\" height=\"10\" width=\"1500\" align=\"center\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "#### **5. Adjusting generation parameters**\n",
    "\n",
    "The `generate()` method provides a lot of parameters to play with to customize the generation process:\n",
    "\n",
    "- `max_length`: Maximum length of the generated text.\n",
    "- `temperature`: Controls randomness. Higher values (e.g., 1.0) make generation more random, while lower values (e.g., 0.7) make it more deterministic.\n",
    "- `num_return_sequences`: Number of independently computed returned sequences. If you want multiple variations of generated text, increase this number.\n",
    "- ... and many more (refer to the Hugging Face documentation for a detailed list).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./images/border.jpg\" height=\"10\" width=\"1500\" align=\"center\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **6. Using other GPT versions**\n",
    "\n",
    "Hugging Face's library supports multiple versions of GPT models like `gpt2`, `gpt2-medium`, `gpt2-large`, and `gpt2-xl`. Simply replace the model name in the `from_pretrained()` function to switch between them.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./images/border.jpg\" height=\"10\" width=\"1500\" align=\"center\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **7. Fine-tuning GPT-2 on AG News Dataset**\n",
    "\n",
    "We will illustrate the process of fine-tuning the GPT-2 model on the \"AG News\" dataset,\n",
    "    - A collection of news articles categorized into four classes. \n",
    "    - This dataset is available in the `torchtext` library. \n",
    "  - We'll slightly modify GPT-2 for classification, but you can use similar steps for different tasks."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./images/border.jpg\" height=\"10\" width=\"1500\" align=\"center\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **1. Setup**\n",
    "\n",
    "Install the necessary packages:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "Requirement already satisfied: transformers in /Users/mzihayat/VSC/Seshat/.conda/lib/python3.10/site-packages (4.33.2)\n",
      "Requirement already satisfied: torch in /Users/mzihayat/VSC/Seshat/.conda/lib/python3.10/site-packages (2.0.1)\n",
      "Requirement already satisfied: torchtext in /Users/mzihayat/VSC/Seshat/.conda/lib/python3.10/site-packages (0.15.2)\n",
      "Requirement already satisfied: filelock in /Users/mzihayat/VSC/Seshat/.conda/lib/python3.10/site-packages (from transformers) (3.12.4)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.15.1 in /Users/mzihayat/VSC/Seshat/.conda/lib/python3.10/site-packages (from transformers) (0.17.2)\n",
      "Requirement already satisfied: numpy>=1.17 in /Users/mzihayat/VSC/Seshat/.conda/lib/python3.10/site-packages (from transformers) (1.25.2)\n",
      "Requirement already satisfied: packaging>=20.0 in /Users/mzihayat/VSC/Seshat/.conda/lib/python3.10/site-packages (from transformers) (23.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /Users/mzihayat/VSC/Seshat/.conda/lib/python3.10/site-packages (from transformers) (6.0.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /Users/mzihayat/VSC/Seshat/.conda/lib/python3.10/site-packages (from transformers) (2023.8.8)\n",
      "Requirement already satisfied: requests in /Users/mzihayat/VSC/Seshat/.conda/lib/python3.10/site-packages (from transformers) (2.31.0)\n",
      "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /Users/mzihayat/VSC/Seshat/.conda/lib/python3.10/site-packages (from transformers) (0.13.3)\n",
      "Requirement already satisfied: safetensors>=0.3.1 in /Users/mzihayat/VSC/Seshat/.conda/lib/python3.10/site-packages (from transformers) (0.3.3)\n",
      "Requirement already satisfied: tqdm>=4.27 in /Users/mzihayat/VSC/Seshat/.conda/lib/python3.10/site-packages (from transformers) (4.66.1)\n",
      "Requirement already satisfied: typing-extensions in /Users/mzihayat/VSC/Seshat/.conda/lib/python3.10/site-packages (from torch) (4.7.1)\n",
      "Requirement already satisfied: sympy in /Users/mzihayat/VSC/Seshat/.conda/lib/python3.10/site-packages (from torch) (1.12)\n",
      "Requirement already satisfied: networkx in /Users/mzihayat/VSC/Seshat/.conda/lib/python3.10/site-packages (from torch) (3.1)\n",
      "Requirement already satisfied: jinja2 in /Users/mzihayat/VSC/Seshat/.conda/lib/python3.10/site-packages (from torch) (3.1.2)\n",
      "Requirement already satisfied: torchdata==0.6.1 in /Users/mzihayat/VSC/Seshat/.conda/lib/python3.10/site-packages (from torchtext) (0.6.1)\n",
      "Requirement already satisfied: urllib3>=1.25 in /Users/mzihayat/VSC/Seshat/.conda/lib/python3.10/site-packages (from torchdata==0.6.1->torchtext) (2.0.4)\n",
      "Requirement already satisfied: fsspec in /Users/mzihayat/VSC/Seshat/.conda/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.15.1->transformers) (2023.9.1)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Users/mzihayat/VSC/Seshat/.conda/lib/python3.10/site-packages (from jinja2->torch) (2.1.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/mzihayat/VSC/Seshat/.conda/lib/python3.10/site-packages (from requests->transformers) (3.2.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/mzihayat/VSC/Seshat/.conda/lib/python3.10/site-packages (from requests->transformers) (3.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/mzihayat/VSC/Seshat/.conda/lib/python3.10/site-packages (from requests->transformers) (2023.7.22)\n",
      "Requirement already satisfied: mpmath>=0.19 in /Users/mzihayat/VSC/Seshat/.conda/lib/python3.10/site-packages (from sympy->torch) (1.3.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install transformers torch torchtext"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./images/border.jpg\" height=\"10\" width=\"1500\" align=\"center\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **2. Importing required modules**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchtext.datasets import AG_NEWS\n",
    "from torchtext.data.utils import get_tokenizer\n",
    "from torchtext.vocab import build_vocab_from_iterator\n",
    "from transformers import GPT2Tokenizer, GPT2Model\n",
    "from torch.utils.data import DataLoader\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./images/border.jpg\" height=\"10\" width=\"1500\" align=\"center\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **3. Preparing the dataset**\n",
    "\n",
    "AG News has labeled news articles under 4 categories. We'll tokenize the articles and prepare DataLoader for training and validation:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "Requirement already satisfied: transformers in /Users/mzihayat/VSC/Seshat/.conda/lib/python3.10/site-packages (4.33.2)\n",
      "Collecting datasets\n",
      "  Obtaining dependency information for datasets from https://files.pythonhosted.org/packages/09/7e/fd4d6441a541dba61d0acb3c1fd5df53214c2e9033854e837a99dd9e0793/datasets-2.14.5-py3-none-any.whl.metadata\n",
      "  Downloading datasets-2.14.5-py3-none-any.whl.metadata (19 kB)\n",
      "Requirement already satisfied: filelock in /Users/mzihayat/VSC/Seshat/.conda/lib/python3.10/site-packages (from transformers) (3.12.4)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.15.1 in /Users/mzihayat/VSC/Seshat/.conda/lib/python3.10/site-packages (from transformers) (0.17.2)\n",
      "Requirement already satisfied: numpy>=1.17 in /Users/mzihayat/VSC/Seshat/.conda/lib/python3.10/site-packages (from transformers) (1.25.2)\n",
      "Requirement already satisfied: packaging>=20.0 in /Users/mzihayat/VSC/Seshat/.conda/lib/python3.10/site-packages (from transformers) (23.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /Users/mzihayat/VSC/Seshat/.conda/lib/python3.10/site-packages (from transformers) (6.0.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /Users/mzihayat/VSC/Seshat/.conda/lib/python3.10/site-packages (from transformers) (2023.8.8)\n",
      "Requirement already satisfied: requests in /Users/mzihayat/VSC/Seshat/.conda/lib/python3.10/site-packages (from transformers) (2.31.0)\n",
      "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /Users/mzihayat/VSC/Seshat/.conda/lib/python3.10/site-packages (from transformers) (0.13.3)\n",
      "Requirement already satisfied: safetensors>=0.3.1 in /Users/mzihayat/VSC/Seshat/.conda/lib/python3.10/site-packages (from transformers) (0.3.3)\n",
      "Requirement already satisfied: tqdm>=4.27 in /Users/mzihayat/VSC/Seshat/.conda/lib/python3.10/site-packages (from transformers) (4.66.1)\n",
      "Requirement already satisfied: pyarrow>=8.0.0 in /Users/mzihayat/VSC/Seshat/.conda/lib/python3.10/site-packages (from datasets) (13.0.0)\n",
      "Collecting dill<0.3.8,>=0.3.0 (from datasets)\n",
      "  Obtaining dependency information for dill<0.3.8,>=0.3.0 from https://files.pythonhosted.org/packages/f5/3a/74a29b11cf2cdfcd6ba89c0cecd70b37cd1ba7b77978ce611eb7a146a832/dill-0.3.7-py3-none-any.whl.metadata\n",
      "  Downloading dill-0.3.7-py3-none-any.whl.metadata (9.9 kB)\n",
      "Requirement already satisfied: pandas in /Users/mzihayat/VSC/Seshat/.conda/lib/python3.10/site-packages (from datasets) (2.0.3)\n",
      "Collecting xxhash (from datasets)\n",
      "  Obtaining dependency information for xxhash from https://files.pythonhosted.org/packages/6c/91/1327b983004ba81afe4b908f086e6c151ab9aa6007704fea7a55d7822be9/xxhash-3.3.0-cp310-cp310-macosx_10_9_x86_64.whl.metadata\n",
      "  Downloading xxhash-3.3.0-cp310-cp310-macosx_10_9_x86_64.whl.metadata (12 kB)\n",
      "Collecting multiprocess (from datasets)\n",
      "  Obtaining dependency information for multiprocess from https://files.pythonhosted.org/packages/35/a8/36d8d7b3e46b377800d8dec47891cdf05842d1a2366909ae4a0c89fbc5e6/multiprocess-0.70.15-py310-none-any.whl.metadata\n",
      "  Downloading multiprocess-0.70.15-py310-none-any.whl.metadata (7.2 kB)\n",
      "Collecting fsspec[http]<2023.9.0,>=2023.1.0 (from datasets)\n",
      "  Obtaining dependency information for fsspec[http]<2023.9.0,>=2023.1.0 from https://files.pythonhosted.org/packages/e3/bd/4c0a4619494188a9db5d77e2100ab7d544a42e76b2447869d8e124e981d8/fsspec-2023.6.0-py3-none-any.whl.metadata\n",
      "  Downloading fsspec-2023.6.0-py3-none-any.whl.metadata (6.7 kB)\n",
      "Collecting aiohttp (from datasets)\n",
      "  Obtaining dependency information for aiohttp from https://files.pythonhosted.org/packages/f3/56/a5a062bc98e8d5848f7790963771f8354f488726a59fd650742ca7391171/aiohttp-3.8.5-cp310-cp310-macosx_10_9_x86_64.whl.metadata\n",
      "  Downloading aiohttp-3.8.5-cp310-cp310-macosx_10_9_x86_64.whl.metadata (7.7 kB)\n",
      "Collecting attrs>=17.3.0 (from aiohttp->datasets)\n",
      "  Using cached attrs-23.1.0-py3-none-any.whl (61 kB)\n",
      "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /Users/mzihayat/VSC/Seshat/.conda/lib/python3.10/site-packages (from aiohttp->datasets) (3.2.0)\n",
      "Collecting multidict<7.0,>=4.5 (from aiohttp->datasets)\n",
      "  Downloading multidict-6.0.4-cp310-cp310-macosx_10_9_x86_64.whl (29 kB)\n",
      "Collecting async-timeout<5.0,>=4.0.0a3 (from aiohttp->datasets)\n",
      "  Obtaining dependency information for async-timeout<5.0,>=4.0.0a3 from https://files.pythonhosted.org/packages/a7/fa/e01228c2938de91d47b307831c62ab9e4001e747789d0b05baf779a6488c/async_timeout-4.0.3-py3-none-any.whl.metadata\n",
      "  Downloading async_timeout-4.0.3-py3-none-any.whl.metadata (4.2 kB)\n",
      "Collecting yarl<2.0,>=1.0 (from aiohttp->datasets)\n",
      "  Downloading yarl-1.9.2-cp310-cp310-macosx_10_9_x86_64.whl (65 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m65.7/65.7 kB\u001b[0m \u001b[31m1.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting frozenlist>=1.1.1 (from aiohttp->datasets)\n",
      "  Obtaining dependency information for frozenlist>=1.1.1 from https://files.pythonhosted.org/packages/a3/5b/c785feda30d9fda8c1b1a11941e91253f59aeaf13e87ebe908d0f3f6c628/frozenlist-1.4.0-cp310-cp310-macosx_10_9_x86_64.whl.metadata\n",
      "  Downloading frozenlist-1.4.0-cp310-cp310-macosx_10_9_x86_64.whl.metadata (5.2 kB)\n",
      "Collecting aiosignal>=1.1.2 (from aiohttp->datasets)\n",
      "  Using cached aiosignal-1.3.1-py3-none-any.whl (7.6 kB)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /Users/mzihayat/VSC/Seshat/.conda/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.15.1->transformers) (4.7.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/mzihayat/VSC/Seshat/.conda/lib/python3.10/site-packages (from requests->transformers) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/mzihayat/VSC/Seshat/.conda/lib/python3.10/site-packages (from requests->transformers) (2.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/mzihayat/VSC/Seshat/.conda/lib/python3.10/site-packages (from requests->transformers) (2023.7.22)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /Users/mzihayat/VSC/Seshat/.conda/lib/python3.10/site-packages (from pandas->datasets) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /Users/mzihayat/VSC/Seshat/.conda/lib/python3.10/site-packages (from pandas->datasets) (2022.7)\n",
      "Requirement already satisfied: tzdata>=2022.1 in /Users/mzihayat/VSC/Seshat/.conda/lib/python3.10/site-packages (from pandas->datasets) (2023.3)\n",
      "Requirement already satisfied: six>=1.5 in /Users/mzihayat/VSC/Seshat/.conda/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\n",
      "Downloading datasets-2.14.5-py3-none-any.whl (519 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m519.6/519.6 kB\u001b[0m \u001b[31m8.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
      "\u001b[?25hDownloading dill-0.3.7-py3-none-any.whl (115 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m115.3/115.3 kB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading aiohttp-3.8.5-cp310-cp310-macosx_10_9_x86_64.whl (365 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m365.8/365.8 kB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0mm\n",
      "\u001b[?25hDownloading multiprocess-0.70.15-py310-none-any.whl (134 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.8/134.8 kB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading xxhash-3.3.0-cp310-cp310-macosx_10_9_x86_64.whl (31 kB)\n",
      "Downloading async_timeout-4.0.3-py3-none-any.whl (5.7 kB)\n",
      "Downloading frozenlist-1.4.0-cp310-cp310-macosx_10_9_x86_64.whl (46 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.9/46.9 kB\u001b[0m \u001b[31m931.2 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading fsspec-2023.6.0-py3-none-any.whl (163 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m163.8/163.8 kB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: xxhash, multidict, fsspec, frozenlist, dill, attrs, async-timeout, yarl, multiprocess, aiosignal, aiohttp, datasets\n",
      "  Attempting uninstall: fsspec\n",
      "    Found existing installation: fsspec 2023.9.1\n",
      "    Uninstalling fsspec-2023.9.1:\n",
      "      Successfully uninstalled fsspec-2023.9.1\n",
      "Successfully installed aiohttp-3.8.5 aiosignal-1.3.1 async-timeout-4.0.3 attrs-23.1.0 datasets-2.14.5 dill-0.3.7 frozenlist-1.4.0 fsspec-2023.6.0 multidict-6.0.4 multiprocess-0.70.15 xxhash-3.3.0 yarl-1.9.2\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install transformers datasets\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading builder script: 100%|██████████| 4.31k/4.31k [00:00<00:00, 16.9MB/s]\n",
      "Downloading metadata: 100%|██████████| 2.17k/2.17k [00:00<00:00, 14.3MB/s]\n",
      "Downloading readme: 100%|██████████| 7.59k/7.59k [00:00<00:00, 12.9MB/s]\n",
      "Downloading data: 100%|██████████| 84.1M/84.1M [00:46<00:00, 1.80MB/s]\n",
      "Generating train split: 100%|██████████| 25000/25000 [00:05<00:00, 4588.28 examples/s] \n",
      "Generating test split: 100%|██████████| 25000/25000 [00:05<00:00, 4629.88 examples/s] \n",
      "Generating unsupervised split: 100%|██████████| 50000/50000 [00:06<00:00, 7949.45 examples/s] \n",
      "Map: 100%|██████████| 25000/25000 [00:28<00:00, 866.59 examples/s]\n",
      "Map: 100%|██████████| 25000/25000 [00:26<00:00, 937.95 examples/s]\n",
      "Map: 100%|██████████| 50000/50000 [00:56<00:00, 887.45 examples/s]\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "from transformers import GPT2Tokenizer\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "tokenizer = GPT2Tokenizer.from_pretrained('gpt2-medium')\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "\n",
    "dataset = load_dataset('imdb')\n",
    "\n",
    "def tokenize_and_format(examples):\n",
    "    encodings = tokenizer(examples['text'], truncation=True, padding='max_length', max_length=256)\n",
    "    encodings['labels'] = examples['label']\n",
    "    return encodings\n",
    "\n",
    "tokenized_datasets = dataset.map(tokenize_and_format, batched=True)\n",
    "tokenized_datasets.set_format(type='torch', columns=['input_ids', 'attention_mask', 'labels'])\n",
    "\n",
    "train_dataloader = DataLoader(tokenized_datasets['train'], shuffle=True, batch_size=8)\n",
    "test_dataloader = DataLoader(tokenized_datasets['test'], batch_size=8)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./images/border.jpg\" height=\"10\" width=\"1500\" align=\"center\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **4. Modifying GPT-2 for classification**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GPT2ForClassification(nn.Module):\n",
    "    def __init__(self, num_labels=2):\n",
    "        super(GPT2ForClassification, self).__init__()\n",
    "        self.gpt2 = GPT2Model.from_pretrained('gpt2-medium')\n",
    "        self.classifier = nn.Linear(self.gpt2.config.hidden_size, num_labels)\n",
    "\n",
    "    def forward(self, input_ids, attention_mask=None):\n",
    "        outputs = self.gpt2(input_ids, attention_mask=attention_mask)\n",
    "        hidden_states = outputs.last_hidden_state\n",
    "        logits = self.classifier(hidden_states[:, -1])\n",
    "        return logits\n",
    "\n",
    "model = GPT2ForClassification()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./images/border.jpg\" height=\"10\" width=\"1500\" align=\"center\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25.0"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "0.001 * len(tokenized_datasets[\"train\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **5. Training the model**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mzihayat/VSC/Seshat/.conda/lib/python3.10/site-packages/transformers/optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "Epoch 1/3 - Training: 100%|██████████| 4/4 [00:47<00:00, 11.89s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3 - Training Loss: 0.0034\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/3 - Testing: 100%|██████████| 4/4 [00:12<00:00,  3.13s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3 - Test Loss: 0.1023 - Test Accuracy: 0.0009\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/3 - Training: 100%|██████████| 4/4 [00:47<00:00, 11.77s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/3 - Training Loss: 0.0012\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/3 - Testing: 100%|██████████| 4/4 [00:13<00:00,  3.49s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/3 - Test Loss: 0.0815 - Test Accuracy: 0.0010\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/3 - Training: 100%|██████████| 4/4 [00:49<00:00, 12.49s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/3 - Training Loss: 0.0002\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/3 - Testing: 100%|██████████| 4/4 [00:14<00:00,  3.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/3 - Test Loss: 0.0674 - Test Accuracy: 0.0009\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "\n",
    "optimizer = AdamW(model.parameters(), lr=5e-5)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "\n",
    "train_dataset_small = tokenized_datasets[\"train\"].shuffle(seed=42).select(range(0, int(0.001 * len(tokenized_datasets[\"train\"]))))\n",
    "train_dataloader_small = DataLoader(train_dataset_small, shuffle=True, batch_size=8)\n",
    "\n",
    "test_dataset_small = tokenized_datasets[\"test\"].shuffle(seed=42).select(range(0, int(0.001 * len(tokenized_datasets[\"train\"]))))\n",
    "test_dataloader_small = DataLoader(test_dataset_small, shuffle=True, batch_size=8)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "num_epochs = 3\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    \n",
    "    # Wrap train_dataloader_small with tqdm for progress visualization\n",
    "    for batch in tqdm(train_dataloader_small, desc=f\"Epoch {epoch+1}/{num_epochs} - Training\"):\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        inputs = batch[\"input_ids\"].to(device)\n",
    "        masks = batch[\"attention_mask\"].to(device)\n",
    "        labels = batch[\"labels\"].to(device)\n",
    "        \n",
    "        logits = model(inputs, attention_mask=masks)\n",
    "        \n",
    "        loss = criterion(logits, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        total_loss += loss.item()\n",
    "    \n",
    "    avg_train_loss = total_loss / len(train_dataloader_small)\n",
    "    print(f\"Epoch {epoch+1}/{num_epochs} - Training Loss: {avg_train_loss:.4f}\")\n",
    "\n",
    "    # Optional: Evaluation on Test Set\n",
    "    model.eval()\n",
    "    total_eval_loss = 0\n",
    "    correct_predictions = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        # Wrap test_dataloader with tqdm for progress visualization\n",
    "        for batch in tqdm(test_dataloader_small, desc=f\"Epoch {epoch+1}/{num_epochs} - Testing\"):\n",
    "            inputs = batch[\"input_ids\"].to(device)\n",
    "            masks = batch[\"attention_mask\"].to(device)\n",
    "            labels = batch[\"labels\"].to(device)\n",
    "\n",
    "            logits = model(inputs, attention_mask=masks)\n",
    "            loss = criterion(logits, labels)\n",
    "            total_eval_loss += loss.item()\n",
    "\n",
    "            _, preds = torch.max(logits, dim=1)\n",
    "            correct_predictions += torch.sum(preds == labels)\n",
    "\n",
    "    avg_eval_loss = total_eval_loss / len(test_dataloader_small)\n",
    "    accuracy = correct_predictions.double() / len(tokenized_datasets[\"test\"])\n",
    "    \n",
    "    print(f\"Epoch {epoch+1}/{num_epochs} - Test Loss: {avg_eval_loss:.4f} - Test Accuracy: {accuracy:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./images/border.jpg\" height=\"10\" width=\"1500\" align=\"center\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Code Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import GPT2Tokenizer, GPT2LMHeadModel\n",
    "\n",
    "# Load pre-trained model and tokenizer\n",
    "model_name = 'gpt2-medium'\n",
    "model = GPT2LMHeadModel.from_pretrained(model_name)\n",
    "tokenizer = GPT2Tokenizer.from_pretrained(model_name)\n",
    "model.eval()\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    model.to('cuda')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_code(prompt, max_length=150, temperature=0.7, top_k=50):\n",
    "    input_ids = tokenizer.encode(prompt, return_tensors=\"pt\")\n",
    "    \n",
    "    if torch.cuda.is_available():\n",
    "        input_ids = input_ids.to('cuda')\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        generated_ids = model.generate(input_ids, max_length=max_length, temperature=temperature, top_k=top_k)\n",
    "    \n",
    "    generated_code = tokenizer.decode(generated_ids[0], skip_special_tokens=True)\n",
    "    return generated_code\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Write a Python function that takes a list of numbers and returns their average:\n",
      "\n",
      ">>> from math import average >>> average = average(1, 2, 3) >>> print average >>> print average >>> print average >>> print average >>> print average >>> print average >>> print average >>> print average >>> print average >>> print average >>> print average >>> print average >>> print average >>> print average >>> print average >>> print average >>> print average >>> print average >>> print average >>> print average >>> print average >>> print average >>> print average >>> print average >>> print average >>> print average >>> print average >>> print average >>> print average >>> print average >>> print average >>> print average >>> print average >>> print average >>> print average >>> print average >>> print average >>> print average >>> print average\n"
     ]
    }
   ],
   "source": [
    "prompt = \"Write a Python function that takes a list of numbers and returns their average:\"\n",
    "generated_function = generate_code(prompt)\n",
    "print(generated_function)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Few Shot Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Few-shot learning aims to make accurate predictions in tasks with very limited labeled training data.\n",
    "\n",
    "\n",
    "**How it Works:**\n",
    "\n",
    "1. **Training Phase:** Train a model on a large and diverse dataset.\n",
    "2. **Adaptation Phase:** Fine-tune the model on a small dataset related to the specific task.\n",
    "\n",
    "**Benefits:**\n",
    "\n",
    "- Overcomes the challenge of data scarcity.\n",
    "- Adapts to new tasks without extensive retraining.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_code_with_examples(prompt, max_length=300, temperature=0.6, top_k=50):\n",
    "    input_ids = tokenizer.encode(prompt, return_tensors=\"pt\")\n",
    "    \n",
    "    if torch.cuda.is_available():\n",
    "        input_ids = input_ids.to('cuda')\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        generated_ids = model.generate(input_ids, max_length=max_length, temperature=temperature, top_k=top_k)\n",
    "    \n",
    "    generated_code = tokenizer.decode(generated_ids[0], skip_special_tokens=True)\n",
    "    return generated_code\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "# Example 1:\n",
      "# Function to add two numbers\n",
      "def add(a, b):\n",
      "    return a + b\n",
      "\n",
      "# Example 2:\n",
      "# Function to check if a number is even\n",
      "def is_even(num):\n",
      "    return num % 2 == 0\n",
      "\n",
      "# Task: Write a Python function that takes a list of numbers and returns their sum:\n",
      "\n",
      "#\n",
      "\n",
      "# def sum(list):\n",
      "\n",
      "#  return sum(list)\n",
      "\n",
      "#\n",
      "\n",
      "# Example 1:\n",
      "\n",
      "# Function to add two numbers\n",
      "\n",
      "def add(a, b):\n",
      "\n",
      "   return a + b\n",
      "\n",
      "# Example 2:\n",
      "\n",
      "# Function to check if a number is even\n",
      "\n",
      "def is_even(num):\n",
      "\n",
      "   return num % 2 == 0\n",
      "\n",
      "# Task: Write a Python function that takes a list of numbers and returns their sum:\n",
      "\n",
      "#\n",
      "\n",
      "# def sum(list):\n",
      "\n",
      "#  return sum(list)\n",
      "\n",
      "#\n",
      "\n",
      "# Example 1:\n",
      "\n",
      "# Function to add two numbers\n",
      "\n",
      "def add(a, b):\n",
      "\n",
      "   return a + b\n",
      "\n",
      "# Example 2:\n",
      "\n",
      "# Function to check if a number is even\n",
      "\n",
      "def is_even(num):\n",
      "\n",
      "   return num % 2 == 0\n",
      "\n",
      "# Task: Write a Python function that takes a list of numbers and\n"
     ]
    }
   ],
   "source": [
    "prompt_with_examples = \"\"\"\n",
    "# Example 1:\n",
    "# Function to add two numbers\n",
    "def add(a, b):\n",
    "    return a + b\n",
    "\n",
    "# Example 2:\n",
    "# Function to check if a number is even\n",
    "def is_even(num):\n",
    "    return num % 2 == 0\n",
    "\n",
    "# Task: Write a Python function that takes a list of numbers and returns their sum:\n",
    "\"\"\"\n",
    "\n",
    "generated_function_with_examples = generate_code_with_examples(prompt_with_examples)\n",
    "print(generated_function_with_examples)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Without Examples:\n",
      " Write a Python function that takes a list of numbers and returns their sum:\n",
      "\n",
      "def sum ( n ): return n * n\n",
      "\n",
      "This function takes a list of numbers and returns the sum of them.\n",
      "\n",
      "The sum function is a very simple function. It takes a list of numbers and returns the sum of them.\n",
      "\n",
      "The sum function is a very simple function. It takes a list of numbers and returns the sum of them.\n",
      "\n",
      "The sum function is a very simple function. It takes a list of numbers and returns the sum of them.\n",
      "\n",
      "The sum function is a very simple function. It takes a list of numbers and returns the sum of them.\n",
      "\n",
      "The sum function is a very simple function. It\n"
     ]
    }
   ],
   "source": [
    "prompt = \"Write a Python function that takes a list of numbers and returns their sum:\"\n",
    "generated_function = generate_code(prompt)\n",
    "print(\"Without Examples:\\n\", generated_function)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "With Examples:\n",
      " \n",
      "# Example 1:\n",
      "# Function to add two numbers\n",
      "def add(a, b):\n",
      "    return a + b\n",
      "\n",
      "# Example 2:\n",
      "# Function to check if a number is even\n",
      "def is_even(num):\n",
      "    return num % 2 == 0\n",
      "\n",
      "# Task: Write a Python function that takes a list of numbers and returns their sum:\n",
      "\n",
      "#\n",
      "\n",
      "# def sum(list):\n",
      "\n",
      "#  return sum(list)\n",
      "\n",
      "#\n",
      "\n",
      "# Example 1:\n",
      "\n",
      "# Function to add two numbers\n",
      "\n",
      "def add(a, b):\n",
      "\n",
      "   return a + b\n",
      "\n",
      "# Example 2:\n",
      "\n",
      "# Function to check if a number is even\n",
      "\n",
      "def is_even(num):\n",
      "\n",
      "   return num % 2 == 0\n",
      "\n",
      "# Task: Write a Python function that takes a list of numbers and returns their sum:\n",
      "\n",
      "#\n",
      "\n",
      "# def sum(list):\n",
      "\n",
      "#  return sum(list)\n",
      "\n",
      "#\n",
      "\n",
      "# Example 1:\n",
      "\n",
      "# Function to add two numbers\n",
      "\n",
      "def add(a, b):\n",
      "\n",
      "   return a + b\n",
      "\n",
      "# Example 2:\n",
      "\n",
      "# Function to check if a number is even\n",
      "\n",
      "def is_even(num):\n",
      "\n",
      "   return num % 2 == 0\n",
      "\n",
      "# Task: Write a Python function that takes a list of numbers and\n"
     ]
    }
   ],
   "source": [
    "print(\"With Examples:\\n\", generated_function_with_examples)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
